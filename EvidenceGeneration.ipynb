{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvidenceGeneration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this project is to generate evidence using Evidence Model.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "mSR7OQxe7Qfv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_YNvnxx7KX0",
        "outputId": "c02dfc7a-c921-4891-bc82-5bc87bcafb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = []\n",
        "with open('/content/gdrive/MyDrive/EvidenceQuery/debatepedia/test_content', \"r\") as d:\n",
        "  for doc in d:\n",
        "    content.append(doc[4:-7])\n",
        "\n",
        "query = []\n",
        "with open('/content/gdrive/MyDrive/EvidenceQuery/debatepedia/test_query', \"r\") as d:\n",
        "  for doc in d:\n",
        "    query.append(doc[4:-7])\n",
        "\n",
        "summary = []\n",
        "with open('/content/gdrive/MyDrive/EvidenceQuery/debatepedia/test_summary', \"r\") as d:\n",
        "  for doc in d:\n",
        "    summary.append(doc[4:-7])\n"
      ],
      "metadata": {
        "id": "4S_8NE3-Ga0I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHQDjoivJ9Fm",
        "outputId": "25fe7c91-4409-41d1-bf97-04988f7a5404"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece==0.1.91"
      ],
      "metadata": {
        "id": "HSVAiDtVKGQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained('/content/gdrive/MyDrive/EvidenceQuery/model').to(device)\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "def generateEvidence (text_document):\n",
        "  input_ids = tokenizer.encode(text_document, padding=True, truncation = True, return_tensors='pt').to(device)\n",
        "  output = model.generate(input_ids, max_length=12, min_length=12, no_repeat_ngram_size= 4)\n",
        "  evidence = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  return evidence\n",
        "\n",
        "#print(summary[200])\n",
        "#print(generateEvidence(content[200]))"
      ],
      "metadata": {
        "id": "6QJlPWHhN7pl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evidence = []\n",
        "\n",
        "for i in range(len(content)):\n",
        "   evidence.append(generateEvidence(content[i]))"
      ],
      "metadata": {
        "id": "HdEtyIAbRsxh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "debatepedia_data = []\n",
        "\n",
        "for i in range(len(content)):\n",
        "  debatepedia_data.append({'src':content[i],'qry':query[i],'tgt':summary[i],'evd':evidence[i]})\n",
        "\n",
        "with open('/content/gdrive/MyDrive/EvidenceQuery/debatepediaEvidence.json', 'w') as fp:\n",
        "  json.dump(debatepedia_data, fp)"
      ],
      "metadata": {
        "id": "EvLDO4LkYfoQ"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}